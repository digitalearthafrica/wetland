{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffca76bc-495d-4e18-a10a-4840d08526b9",
   "metadata": {},
   "source": [
    "# Create a wetland type map\n",
    "\n",
    "### Background\n",
    "This notebook can be used to generate wetland type map over a region defined by a vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c39902f6-896e-4746-a086-b9929c82cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import rasterio\n",
    "import datacube\n",
    "import warnings\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import load\n",
    "from odc.algo import xr_geomedian\n",
    "from odc.dscache.tools import tiling\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.colors import ListedColormap,BoundaryNorm\n",
    "from datacube.utils import geometry\n",
    "from datacube.utils.cog import write_cog\n",
    "from datacube.utils.geometry import Geometry\n",
    "from datacube.utils.geometry import BoundingBox, Geometry\n",
    "from deafrica_tools.spatial import xr_rasterize\n",
    "from datacube.testutils.io import rio_slurp_xarray\n",
    "from deafrica_tools.classification import predict_xr\n",
    "from deafrica_tools.dask import create_local_dask_cluster\n",
    "from deafrica_tools.datahandling import load_ard\n",
    "from deafrica_tools.bandindices import calculate_indices\n",
    "from deafrica_tools.plotting import rgb, display_map\n",
    "from deafrica_tools.areaofinterest import define_area\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff83fb0-f9aa-458d-820d-3d841b70091e",
   "metadata": {},
   "source": [
    "## Create Dask cluster for running predictions\n",
    "We use dask to parallel and speed up processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57fabf0f-6bcd-4733-ba24-b4973031f4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-8c21cca4-fc3f-11ee-a94b-465330a22d64</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> distributed.LocalCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"/user/mpho.sadiki@digitalearthafrica.org/proxy/8787/status\" target=\"_blank\">/user/mpho.sadiki@digitalearthafrica.org/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"/user/mpho.sadiki@digitalearthafrica.org/proxy/8787/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">LocalCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">2490da81</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"/user/mpho.sadiki@digitalearthafrica.org/proxy/8787/status\" target=\"_blank\">/user/mpho.sadiki@digitalearthafrica.org/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 1\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 15\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 97.21 GiB\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "    <td style=\"text-align: left;\"><strong>Status:</strong> running</td>\n",
       "    <td style=\"text-align: left;\"><strong>Using processes:</strong> True</td>\n",
       "</tr>\n",
       "\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-5c76b45a-e469-4301-ae7d-2daf0eb6d0ff</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://127.0.0.1:38177\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 1\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"/user/mpho.sadiki@digitalearthafrica.org/proxy/8787/status\" target=\"_blank\">/user/mpho.sadiki@digitalearthafrica.org/proxy/8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 15\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 97.21 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 0</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:46281\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 15\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"/user/mpho.sadiki@digitalearthafrica.org/proxy/35569/status\" target=\"_blank\">/user/mpho.sadiki@digitalearthafrica.org/proxy/35569/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 97.21 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:35285\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-worker-space/worker-iakpcggo\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:38177' processes=1 threads=15, memory=97.21 GiB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up a dask cluster\n",
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4197f6b4-86ea-4a7a-b717-352eeb5ad6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app='wetland_classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78b8ce3-0c31-4810-ba6e-e5d44ea2f5c2",
   "metadata": {},
   "source": [
    "## Load the model \n",
    "We use the model trained and saved in the [Train_Classification_Algorithm](04_Train_Classification_Algorithm.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f1f191-87f4-4d96-9568-d4f3e8c31659",
   "metadata": {},
   "source": [
    "### Load area of interest (AOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be56683-7d32-4a57-a094-26d30e202ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'Rwanda'  # Specify the desired prefix - name of area of interest (aoi) is best to ensure the files have the aoi prefix when saved\n",
    "\n",
    "# Method 1: Specify the latitude, longitude, and buffer\n",
    "# aoi = define_area(lat=-1.8948, lon=29.9213, buffer=0.1)\n",
    "\n",
    "# Method 2: Use a polygon as a GeoJSON or Esri Shapefile. \n",
    "aoi = define_area(vector_path=\"data/rwanda.geojson\")\n",
    "\n",
    "#Create a geopolygon and geodataframe of the area of interest\n",
    "geom = Geometry(aoi[\"features\"][0][\"geometry\"], crs=\"epsg:4326\")\n",
    "geom_gdf = gpd.GeoDataFrame(geometry=[geom], crs=geom.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f080b65-4f2c-481b-a313-82d73ade07b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.6.0/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.6.0/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_34695214fa93272cca1593f8bb03d3f9 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_34695214fa93272cca1593f8bb03d3f9&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_34695214fa93272cca1593f8bb03d3f9 = L.map(\n",
       "                &quot;map_34695214fa93272cca1593f8bb03d3f9&quot;,\n",
       "                {\n",
       "                    center: [-1.9438970000000002, 29.880759500000003],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 8,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_7796de8d2ea7ce76fdb52aa4ffd304cb = L.tileLayer(\n",
       "                &quot;http://mt1.google.com/vt/lyrs=y\\u0026z={z}\\u0026x={x}\\u0026y={y}&quot;,\n",
       "                {&quot;attribution&quot;: &quot;Google&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            ).addTo(map_34695214fa93272cca1593f8bb03d3f9);\n",
       "        \n",
       "    \n",
       "            var poly_line_b5b55828aadc55a3d1c2e9c7f5947c7e = L.polyline(\n",
       "                [[-2.839881, 28.861869], [-2.839881, 30.89965], [-1.047913, 30.89965], [-1.047913, 28.861869], [-2.839881, 28.861869]],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;red&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;red&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;noClip&quot;: false, &quot;opacity&quot;: 0.8, &quot;smoothFactor&quot;: 1.0, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_34695214fa93272cca1593f8bb03d3f9);\n",
       "        \n",
       "    \n",
       "                var lat_lng_popup_e2467ad2ee558bbbbc8e7212806164f6 = L.popup();\n",
       "                function latLngPop(e) {\n",
       "                    lat_lng_popup_e2467ad2ee558bbbbc8e7212806164f6\n",
       "                        .setLatLng(e.latlng)\n",
       "                        .setContent(&quot;Latitude: &quot; + e.latlng.lat.toFixed(4) +\n",
       "                                    &quot;&lt;br&gt;Longitude: &quot; + e.latlng.lng.toFixed(4))\n",
       "                        .openOn(map_34695214fa93272cca1593f8bb03d3f9);\n",
       "                    }\n",
       "                map_34695214fa93272cca1593f8bb03d3f9.on(&#x27;click&#x27;, latLngPop);\n",
       "            \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7fd4d771dd50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the latitude and longitude range of the geopolygon\n",
    "lat_range = (geom_gdf.total_bounds[1], geom_gdf.total_bounds[3])\n",
    "lon_range = (geom_gdf.total_bounds[0], geom_gdf.total_bounds[2])\n",
    "display_map(x=lon_range, y=lat_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aca2b60-0ed6-4707-a8e9-cd744d6a3c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded binary random forest model:\n",
      " RandomForestClassifier(n_estimators=50, n_jobs=1, random_state=1)\n",
      "Loaded type random forest model:\n",
      " RandomForestClassifier(n_jobs=1, random_state=1)\n"
     ]
    }
   ],
   "source": [
    "# Check if both binary and type models are available\n",
    "if os.path.exists(f'results/{prefix}_Binary_RF_model.joblib') and os.path.exists(f'results/{prefix}_Type_RF_model.joblib'):\n",
    "    binary_model = load(f'results/{prefix}_Binary_RF_model.joblib').set_params(n_jobs=1)\n",
    "    print('Loaded binary random forest model:\\n', binary_model)\n",
    "\n",
    "    type_model = load(f'results/{prefix}_Type_RF_model.joblib').set_params(n_jobs=1)\n",
    "    print('Loaded type random forest model:\\n', type_model)\n",
    "elif os.path.exists(f'results/{prefix}_Binary_RF_model.joblib'):\n",
    "    binary_model = load(f'results/{prefix}_Binary_RF_model.joblib').set_params(n_jobs=1)\n",
    "    print('Loaded binary random forest model:\\n', binary_model)\n",
    "elif os.path.exists(f'results/{prefix}_Type_RF_model.joblib'):\n",
    "    type_model = load(f'results/{prefix}_Type_RF_model.joblib').set_params(n_jobs=1)\n",
    "    print('Loaded type random forest model:\\n', type_model)\n",
    "else:\n",
    "    print(\"No trained models found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "078c8e0b-9aa6-4273-857d-163bd1b58b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded binary model features.\n",
      "Loaded type model features.\n"
     ]
    }
   ],
   "source": [
    "# Define the file paths for importing the feature names\n",
    "binary_features_path = f\"results/{prefix}_binary_model_features.json\"\n",
    "type_features_path = f\"results/{prefix}_type_model_features.json\"\n",
    "\n",
    "# Load binary model feature names from JSON if binary model exists\n",
    "if os.path.exists(binary_features_path):\n",
    "    with open(binary_features_path, \"r\") as binary_file:\n",
    "        binary_features_dict = json.load(binary_file)\n",
    "    binary_feature_names = binary_features_dict[\"features\"]\n",
    "    print(\"Loaded binary model features.\")\n",
    "else:\n",
    "    print(\"No binary model features found.\")\n",
    "\n",
    "# Load type model feature names from JSON if type model exists\n",
    "if os.path.exists(type_features_path):\n",
    "    with open(type_features_path, \"r\") as type_file:\n",
    "        type_features_dict = json.load(type_file)\n",
    "    type_feature_names = type_features_dict[\"features\"]\n",
    "    print(\"Loaded type model features.\")\n",
    "else:\n",
    "    print(\"No type model features found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e4075e-e7a9-4001-9ade-8a849e9350cc",
   "metadata": {},
   "source": [
    "### Break area of interest into tiles for smaller processing chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39e520a5-bffa-4d9d-9541-644c43400981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a gridspec from string and convert to geoms\n",
    "tiles = tiling.parse_gridspec(s=\"epsg:6933;20;1024\")\n",
    "tiles.tile_coords(tile_index=(0, 0))\n",
    "tiles = tiles.tiles_from_geopolygon(geom)\n",
    "geoms = (i[1].extent.geom for i in tiles)\n",
    "\n",
    "geoms_df = gpd.GeoDataFrame(geometry=list(geoms))\n",
    "\n",
    "# Set the CRS to EPSG:6933\n",
    "geoms_df.crs = \"EPSG:6933\"\n",
    "\n",
    "geoms_df.to_file(f\"data/{prefix}_tiles.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "# Plot the geometries\n",
    "geoms_df.plot()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce884b3-427b-4164-9582-bf3e145fc2c0",
   "metadata": {},
   "source": [
    "## Create the query for running the predictions\n",
    "\n",
    "We use the query saved from the feature extraction notebook to ensure data from the same periods are retrieved. However, only selected features will be used. \n",
    "\n",
    "> We add `dask_chunks` to the query parameter so the data will be lazy-loaded and only the features used by the model will be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d65b75f-5276-42d1-823a-908aa2bc70f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = ('2022')\n",
    "# using nine spectral bands with 10~20 m spatial resolution\n",
    "resolution = (-20,20)\n",
    "output_crs='epsg:6933'\n",
    "\n",
    "def feature_layers(query):\n",
    "    # connect to the datacube\n",
    "#     dc = datacube.Datacube(app='feature_layers')\n",
    "    \n",
    "    # load s2 annual geomedian\n",
    "    ds = dc.load(\n",
    "        product='gm_s2_annual',\n",
    "        measurements = ['blue','green','red','red_edge_1','red_edge_2', 'red_edge_3','nir_1','nir_2','swir_1','swir_2','emad','smad','bcmad'],\n",
    "        **query)\n",
    "    \n",
    "    # calculate some band indices\n",
    "    ds = calculate_indices(ds,\n",
    "                           index=['NDVI', 'MNDWI','TCW'],\n",
    "                           drop=False,\n",
    "                           satellite_mission='s2')\n",
    "    \n",
    "    \n",
    "    # Add a prefix \"Annual\" to the band names\n",
    "    new_band_names = ['Annual_' + band_name for band_name in ds.data_vars]\n",
    "    ds = ds.rename({old_band_name: new_band_name for old_band_name, new_band_name in zip(ds.data_vars, new_band_names)})\n",
    "\n",
    "    # stack multi-temporal measurements and rename them\n",
    "    n_time = ds.dims['time']\n",
    "    list_measurements = list(ds.keys())\n",
    "    list_stack_measures = []\n",
    "    for j in range(len(list_measurements)):\n",
    "        for k in range(n_time):\n",
    "            variable_name = list_measurements[j]+'_'+str(k)\n",
    "            measure_single = ds[list_measurements[j]].isel(time=k).rename(variable_name)\n",
    "            list_stack_measures.append(measure_single)\n",
    "    ds_stacked = xr.merge(list_stack_measures, compat='override')\n",
    "\n",
    "    \n",
    "    # Load the Sentinel-1 data    \n",
    "    ds_s1 = dc.load(product=[\"s1_rtc\"],\n",
    "                  measurements=['vv', 'vh'],\n",
    "                  group_by=\"solar_day\",\n",
    "                  **query\n",
    "                 )\n",
    "    # Add a prefix \"Sent1_\" to the variables in ds_s1\n",
    "    ds_s1 = ds_s1.rename({old_var: 'sent1_' + old_var for old_var in ds_s1.data_vars})\n",
    "\n",
    "    # median values are used to scale the measurements so they have a similar range for visualization\n",
    "    med_s1 = ds_s1[['sent1_vv','sent1_vh']].median(dim='time')\n",
    "    \n",
    "    # Add ALOS L-Band Annual mosaic\n",
    "    ds_alos = dc.load(product='alos_palsar_mosaic',\n",
    "                      measurements=['hh','hv'],\n",
    "                      **query)\n",
    "    \n",
    "    # Add a prefix \"Sent1_\" to the variables in ds_s1\n",
    "    ds_alos = ds_alos.rename({old_var: 'alos_' + old_var for old_var in ds_alos.data_vars})\n",
    "        \n",
    "    med_alos = ds_alos[['alos_hh','alos_hv']].median(dim='time')\n",
    "    \n",
    "\n",
    "    # Add WOfS Annual summary\n",
    "    wofs_annual = dc.load(product='wofs_ls_summary_annual',\n",
    "               like=ds.geobox,\n",
    "               time=query['time'])\n",
    "    wofs_annual_frequency = wofs_annual.frequency\n",
    "    wofs_annual_frequency.name = 'WOfS_annual_frequency'\n",
    "    \n",
    "    \n",
    "    # loop through the terrain attribite files and add them to the dataset\n",
    "    folder = os.path.join(\"data/terrain_attributes/\", prefix)\n",
    "    for filename in os.listdir(folder):\n",
    "            if filename.endswith('.tif'):\n",
    "                filepath = os.path.join(folder, filename)\n",
    "                tif = rio_slurp_xarray(filepath, gbox=ds.geobox)\n",
    "                tif = tif.to_dataset(name=filename.replace('.tif', ''))\n",
    "                ds_stacked = xr.merge([ds_stacked, tif], compat='override')\n",
    "\n",
    "\n",
    "    # merge all the datasets into a single dataset\n",
    "    ds_stacked = xr.merge([ds_stacked, med_s1, med_alos, wofs_annual_frequency], compat='override')\n",
    "\n",
    "    return ds_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4035da-63d8-45a4-9492-fc25e2bd4f85",
   "metadata": {},
   "source": [
    "## Apply classification model to predict wetlands in the AOI\n",
    "\n",
    "The model will be applied over each tile, producing a prediction map and a probabilities map. The maps are saved as Cloud-Optimized Geotiffs (COGs).\n",
    "\n",
    "> Tiles are processed in sequence. For each tile, the processing needs to fit into the compute resources available in the sandbox. Make the tile size smaller if you run out of memory. For production of a map over a large region or country, consider applying for [a large sandbox (with more CPUs and momery)](\n",
    "https://helpdesk.digitalearthafrica.org/portal/en/community/topic/call-for-application-for-access-to-large-sandboxes-15-processing-cores-and-120-gb-of-memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e409f83-f633-445f-8e22-639b4f578111",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_existing = False\n",
    "output_folder = \"results\"\n",
    "binary_tiles_pred_folder = os.path.join(output_folder, f\"{prefix}/binary_tiles_predicted\")\n",
    "os.makedirs(binary_tiles_pred_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39037b1-b35d-4b09-a7ef-10419564b00c",
   "metadata": {},
   "source": [
    "## Binary classification\n",
    "#### Binary predictions and probabilities per tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66fd684-20ba-42b7-be99-fc01daa776a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting... Polygon 4 of 87\n",
      "predicting...\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "dask_chunks = {'x':2500,'y':2500}\n",
    "\n",
    "# generate a datacube query object\n",
    "query = {\n",
    "    'geopolygon': geom,\n",
    "    'time': time,\n",
    "    'resolution': resolution,\n",
    "    'output_crs': output_crs,\n",
    "    'dask_chunks': dask_chunks,\n",
    "}\n",
    "\n",
    "for index in range(len(geoms_df)):   # Iterate over the tiles\n",
    "    aoi = geoms_df.iloc[index]\n",
    "#     print(f\"Processing Polygon {index + 1} of {len(geoms_df)}\")\n",
    "    progress_text = f\"Predicting... Polygon {index + 1} of {len(geoms_df)}\"\n",
    "    print(progress_text)\n",
    "    \n",
    "    # Check if polygon has already been processed. If so, skip\n",
    "    output_filename = os.path.join(\n",
    "        binary_tiles_pred_folder, f\"{prefix}_tile{index:03d}_wetland_binary_prediction.tif\")\n",
    "    probabilities_filename = os.path.join(\n",
    "        binary_tiles_pred_folder, f\"{prefix}_tile{index:03d}_wetland_binary_probabilities.tif\")\n",
    "    if skip_existing and os.path.exists(output_filename) and os.path.exists(probabilities_filename):\n",
    "        print(\"Completed; Skipping\")\n",
    "        continue\n",
    "\n",
    "    # set up query based on aoi geometry\n",
    "    geom = geometry.Geometry(geom=aoi.geometry, crs=geoms_df.crs)\n",
    "    query.update({\"geopolygon\": geom})\n",
    "    \n",
    "    # calculate features\n",
    "    data = feature_layers(query).persist()\n",
    "    \n",
    "    # Only keep features that are in the original list of columns\n",
    "    data = data[binary_feature_names]\n",
    "\n",
    "    # Convert xarray Dataset object to Dask array\n",
    "    data_dask = data.chunk(dask_chunks)\n",
    "\n",
    "    # predict using the imported model\n",
    "    predicted = predict_xr(binary_model,\n",
    "                           data_dask,\n",
    "                           proba=True,\n",
    "                           persist=True,\n",
    "                           clean=True,\n",
    "                           return_input=True\n",
    "                           ).compute().persist()\n",
    "    \n",
    "    # Create a mask for the aoi\n",
    "    print(\"    Getting AOI mask\")\n",
    "    aoi_mask = xr_rasterize(\n",
    "        gdf=gpd.GeoDataFrame({\"Polygon\": [index], \"geometry\": [\n",
    "                             aoi.geometry]}, crs=geoms_df.crs),\n",
    "        da=predicted,\n",
    "        crs=output_crs,\n",
    "    )\n",
    "\n",
    "    # set the no data value\n",
    "    NODATA = 255\n",
    "\n",
    "    # Mask the predictions\n",
    "    print(\"    Preparing predictions\")\n",
    "    predicted_masked = (\n",
    "        predicted.Predictions.where(aoi_mask == 1, NODATA)\n",
    "    )\n",
    "    predicted_masked.attrs[\"nodata\"] = NODATA\n",
    "\n",
    "    # Write predictions to COG\n",
    "    print(f\"    Writing predictions to {output_filename}\")\n",
    "    write_cog(\n",
    "        predicted_masked,\n",
    "        fname=output_filename,\n",
    "        overwrite=True,\n",
    "        nodata=255,\n",
    "    )\n",
    "\n",
    "    del predicted_masked\n",
    "\n",
    "    # Mask the probabilities\n",
    "    probability_masked = (\n",
    "        predicted.Probabilities.where(aoi_mask == 1, NODATA)\n",
    "    )\n",
    "    probability_masked.attrs[\"nodata\"] = NODATA\n",
    "\n",
    "    print(f\"    Writing probabilities to {probabilities_filename}\")\n",
    "    write_cog(\n",
    "        probability_masked,\n",
    "        fname=probabilities_filename,\n",
    "        overwrite=True,\n",
    "        nodata=255,\n",
    "    )\n",
    "\n",
    "\n",
    "    del probability_masked\n",
    "\n",
    "    del aoi_mask\n",
    "    \n",
    "    # Clear the output\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa0c0d3-48ba-44ab-887e-bc39db44e8a0",
   "metadata": {},
   "source": [
    "#### Merge the tiles and export the final wetland predictions and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e682de-5335-4d88-86a5-46d208b43f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip_existing = False\n",
    "\n",
    "# Get the list of files in the tiles_pred folder\n",
    "tile_files = os.listdir(binary_tiles_pred_folder)\n",
    "\n",
    "# Create a list to store the paths of prediction and probability files\n",
    "prediction_files = []\n",
    "probability_files = []\n",
    "\n",
    "# Define the pattern for matching the filenames\n",
    "pattern_prediction = fr\"{prefix}_tile\\d+_wetland_binary_prediction.tif\"\n",
    "pattern_probability = fr\"{prefix}_tile\\d+_wetland_binary_probabilities.tif\"\n",
    "\n",
    "# Compile the regular expression patterns\n",
    "regex_prediction = re.compile(pattern_prediction)\n",
    "regex_probability = re.compile(pattern_probability)\n",
    "\n",
    "# Iterate over the tile files\n",
    "for file in tile_files:\n",
    "    # Check if the file is a prediction file\n",
    "    if regex_prediction.match(file):\n",
    "        prediction_files.append(os.path.join(binary_tiles_pred_folder, file))\n",
    "    # Check if the file is a probability file\n",
    "    elif regex_probability.match(file):\n",
    "        probability_files.append(os.path.join(binary_tiles_pred_folder, file))\n",
    "\n",
    "# Define the output mosaic filenames\n",
    "out_mosaic_prediction = f\"{output_folder}/{prefix}/{prefix}_merged_wetland_binary_prediction.tif\"\n",
    "out_mosaic_probabilities = f\"{output_folder}/{prefix}/{prefix}_merged_wetland_binary_probabilities.tif\"\n",
    "\n",
    "# Remove the merged files if they already exist\n",
    "if os.path.exists(out_mosaic_prediction):\n",
    "    subprocess.run(f\"rm {out_mosaic_prediction}\", shell=True)\n",
    "\n",
    "if os.path.exists(out_mosaic_probabilities):\n",
    "    subprocess.run(f\"rm {out_mosaic_probabilities}\", shell=True)\n",
    "\n",
    "# Merge the individual tiles into the merged files\n",
    "merge_cmd_prediction = f\"gdal_merge.py -o {out_mosaic_prediction} -co COMPRESS=Deflate -ot Byte {' '.join(prediction_files)} -init 255 -a_nodata 255\"\n",
    "subprocess.run(merge_cmd_prediction, shell=True)\n",
    "\n",
    "merge_cmd_probabilities = f\"gdal_merge.py -o {out_mosaic_probabilities} -co COMPRESS=Deflate -ot Byte {' '.join(probability_files)} -init 255 -a_nodata 255\"\n",
    "subprocess.run(merge_cmd_probabilities, shell=True)\n",
    "\n",
    "# Load the merged predictions as xarray DataArray\n",
    "merged_prediction = rxr.open_rasterio(out_mosaic_prediction).squeeze()\n",
    "merged_probabilities = rxr.open_rasterio(out_mosaic_probabilities).squeeze()\n",
    "\n",
    "# Rasterize the area of interest polygon\n",
    "aoi_raster = xr_rasterize(gdf=geom_gdf,\n",
    "                          da=merged_prediction,\n",
    "                          crs=merged_prediction.rio.crs)\n",
    "\n",
    "\n",
    "# Mask the wetland classes pixels within the AOI\n",
    "binary_wetland_predictions = merged_prediction.where((~np.isnan(merged_prediction)) &\n",
    "                                                      (aoi_raster != 0))\n",
    "\n",
    "# Define the output clipped filenames\n",
    "clipped_prediction_file = f\"{output_folder}/{prefix}/{prefix}_wetland_binary_prediction.tif\"\n",
    "clipped_probabilities_file = f\"{output_folder}/{prefix}/{prefix}_wetland_binary_probabilities.tif\"\n",
    "\n",
    "# Write the clipped wetland predictions to file\n",
    "write_cog(\n",
    "    binary_wetland_predictions,\n",
    "    fname=clipped_prediction_file,\n",
    "    overwrite=True,\n",
    "    nodata=255,\n",
    ")\n",
    "\n",
    "# Clip the wetland probabilities to the AOI\n",
    "binary_wetland_probabilities = merged_probabilities.where((~np.isnan(merged_prediction)) &\n",
    "                                                      (aoi_raster != 0))\n",
    "\n",
    "# Write the clipped wetland probabilities to file\n",
    "write_cog(\n",
    "    binary_wetland_probabilities,\n",
    "    fname=clipped_probabilities_file,\n",
    "    overwrite=True,\n",
    "    nodata=255,\n",
    ")\n",
    "\n",
    "# Delete the merged files\n",
    "if os.path.exists(out_mosaic_prediction):\n",
    "    os.remove(out_mosaic_prediction)\n",
    "\n",
    "if os.path.exists(out_mosaic_probabilities):\n",
    "    os.remove(out_mosaic_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f549f44-af9d-4211-88f4-f81552c60082",
   "metadata": {},
   "source": [
    "#### Plot the wetland predicition and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c44a25-0535-4c65-849e-9b2356b14aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new label dictionary\n",
    "labels_dict_binary = {'Non-wetland': 0, 'Wetland': 1}\n",
    "\n",
    "# Generate random colors for each class (excluding class 0)\n",
    "random.seed(42)  # Set a seed for reproducibility\n",
    "class_colors = {class_name: f'#{random.randint(0, 255):02x}{random.randint(0, 255):02x}{random.randint(0, 255):02x}'\n",
    "                for class_name in labels_dict_binary}\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot wetland predictions\n",
    "# Sort classes based on their numeric labels\n",
    "sorted_classes = sorted(labels_dict_binary, key=lambda x: labels_dict_binary[x])\n",
    "\n",
    "# Plot wetland predictions\n",
    "cmap = ListedColormap([class_colors[class_name] for class_name in sorted_classes])\n",
    "binary_wetland_predictions.plot.imshow(ax=axes[0],\n",
    "                                cmap=cmap,\n",
    "                                add_colorbar=False,\n",
    "                                interpolation='none')\n",
    "axes[0].set_title('Wetland Predictions', fontweight='bold')\n",
    "\n",
    "# Plot clipped wetland probabilities\n",
    "im = binary_wetland_probabilities.plot.imshow(ax=axes[1],\n",
    "                                       cmap='RdYlBu',\n",
    "                                       add_colorbar=False)\n",
    "axes[1].set_title('Wetland Probabilities', fontweight='bold')\n",
    "\n",
    "# Add legend to the first subplot\n",
    "patches_list = [Patch(facecolor=class_colors[class_name]) for class_name in sorted_classes]\n",
    "legend = axes[0].legend(patches_list, [class_name for class_name in sorted_classes],\n",
    "                        loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Adjust spacing\n",
    "fig.tight_layout()\n",
    "\n",
    "# Add colorbar outside the subplot\n",
    "cbar = fig.colorbar(im, ax=axes.ravel().tolist(), orientation='vertical', fraction=0.05, pad=0.04)\n",
    "cbar.set_label('Wetland Probability')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3002ca8-44a2-46df-b5a8-c6db86350289",
   "metadata": {},
   "source": [
    "### Independent accuaracy assessment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687b6bc2-5f01-4576-a342-97dc00e6da6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the testing points GeoDataFrame\n",
    "testing_points = gpd.read_file(f'data/{prefix}_testing_samples.geojson')\n",
    "\n",
    "# Replace non-zero values in the 'class_id' column with 1\n",
    "testing_points['class_id_binary'] = testing_points['class_id'].apply(lambda x: 1 if x != 0 else 0)\n",
    "# Insert the new column at the second position\n",
    "testing_points.insert(1, 'class_id_binary', testing_points.pop('class_id_binary'))\n",
    "\n",
    "# Sample the predictions and probabilities at testing points\n",
    "sampled_predictions = []\n",
    "sampled_probabilities = []\n",
    "\n",
    "for point in testing_points.geometry:\n",
    "    # Extract the point coordinates\n",
    "    x, y = point.x, point.y\n",
    "    \n",
    "    # Sample the binary predictions and probabilities at the point coordinates\n",
    "    prediction = binary_wetland_predictions.sel(x=x, y=y, method='nearest').item()\n",
    "    probability = binary_wetland_probabilities.sel(x=x, y=y, method='nearest').item()\n",
    "    \n",
    "    # Append the sampled values\n",
    "    sampled_predictions.append(prediction)\n",
    "    sampled_probabilities.append(probability)\n",
    "\n",
    "# Add the sampled values as new columns in the GeoDataFrame\n",
    "testing_points['sampled_predictions'] = sampled_predictions\n",
    "testing_points['sampled_probabilities'] = sampled_probabilities\n",
    "\n",
    "# Calculate the number of correctly classified samples\n",
    "correct_count = (testing_points['sampled_predictions'] == testing_points['class_id_binary']).sum()\n",
    "\n",
    "# Calculate the total number of samples\n",
    "total_count = len(testing_points)\n",
    "\n",
    "# Calculate the accuracy as a percentage\n",
    "accuracy_percentage = (correct_count / total_count) * 100\n",
    "\n",
    "# Print the accuracy percentage\n",
    "print(f\"Overall Accuracy: {accuracy_percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a27929e-9659-457c-9e07-cce33e811ef9",
   "metadata": {},
   "source": [
    "## Wetland Type classification\n",
    "#### Applied to the wetland class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb02cb0-dbc8-47f4-841e-341cdddf570f",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Check if type_model exists\n",
    "if 'type_model' in locals():   \n",
    "    tiles_pred_folder = os.path.join(output_folder, f\"{prefix}/type_tiles_predicted\")\n",
    "    os.makedirs(tiles_pred_folder, exist_ok=True)\n",
    "\n",
    "    predictions = []\n",
    "    dask_chunks = {'x':2500,'y':2500}\n",
    "\n",
    "    # generate a datacube query object\n",
    "    query = {\n",
    "        'geopolygon': geom,\n",
    "        'time': time,\n",
    "        'resolution': resolution,\n",
    "        'output_crs': output_crs,\n",
    "        'dask_chunks': dask_chunks,\n",
    "    }\n",
    "\n",
    "    for index in range(len(geoms_df)):   # Iterate over the tiles\n",
    "        aoi = geoms_df.iloc[index]\n",
    "    #     print(f\"Processing Polygon {index + 1} of {len(geoms_df)}\")\n",
    "        progress_text = f\"Predicting... Polygon {index + 1} of {len(geoms_df)}\"\n",
    "        print(progress_text)\n",
    "\n",
    "        # Check if polygon has already been processed. If so, skip\n",
    "        output_filename = os.path.join(\n",
    "            tiles_pred_folder, f\"{prefix}_tile{index:03d}_wetland_type_prediction.tif\")\n",
    "        probabilities_filename = os.path.join(\n",
    "            tiles_pred_folder, f\"{prefix}_tile{index:03d}_wetland_type_probabilities.tif\")\n",
    "        if skip_existing and os.path.exists(output_filename) and os.path.exists(probabilities_filename):\n",
    "            print(\"Completed; Skipping\")\n",
    "            continue\n",
    "\n",
    "        # set up query based on aoi geometry\n",
    "        geom = geometry.Geometry(geom=aoi.geometry, crs=geoms_df.crs)\n",
    "        query.update({\"geopolygon\": geom})\n",
    "\n",
    "        # set the no data value\n",
    "        NODATA = 255\n",
    "\n",
    "        # calculate features\n",
    "        data = feature_layers(query).persist()\n",
    "\n",
    "        # Clip the data to the extent of wetland predictions\n",
    "        data = data.where(binary_wetland_predictions == 1)\n",
    "\n",
    "        # Only keep features that are in the original list of columns\n",
    "        data = data[type_feature_names]\n",
    "\n",
    "        # Convert xarray Dataset object to Dask array\n",
    "        data_dask = data.chunk(dask_chunks)\n",
    "\n",
    "        # predict using the imported model\n",
    "        predicted = predict_xr(type_model,\n",
    "                               data_dask,\n",
    "                               proba=True,\n",
    "                               persist=True,\n",
    "                               clean=True,\n",
    "                               return_input=True\n",
    "                               ).compute().persist()\n",
    "\n",
    "        # Create a mask for the aoi\n",
    "        print(\"    Getting AOI mask\")\n",
    "        aoi_mask = xr_rasterize(\n",
    "            gdf=gpd.GeoDataFrame({\"Polygon\": [index], \"geometry\": [\n",
    "                                 aoi.geometry]}, crs=geoms_df.crs),\n",
    "            da=predicted,\n",
    "            crs=output_crs,\n",
    "        )\n",
    "\n",
    "\n",
    "        # Mask the predictions with both AOI mask and wetland predictions mask\n",
    "        print(\"    Preparing predictions\")\n",
    "        predicted_masked = (\n",
    "            predicted.Predictions.where((aoi_mask == 1) & (binary_wetland_predictions == 1), NODATA)\n",
    "        )\n",
    "        predicted_masked.attrs[\"nodata\"] = NODATA\n",
    "\n",
    "        # Write predictions to COG\n",
    "        print(f\"    Writing predictions to {output_filename}\")\n",
    "        write_cog(\n",
    "            predicted_masked,\n",
    "            fname=output_filename,\n",
    "            overwrite=True,\n",
    "            nodata=255,\n",
    "        )\n",
    "\n",
    "        del predicted_masked\n",
    "\n",
    "        # Mask the probabilities with both AOI mask and wetland predictions mask\n",
    "        probability_masked = (\n",
    "            predicted.Probabilities.where((aoi_mask == 1) & (binary_wetland_predictions == 1), NODATA)\n",
    "        )\n",
    "        probability_masked.attrs[\"nodata\"] = NODATA\n",
    "\n",
    "        print(f\"    Writing probabilities to {probabilities_filename}\")\n",
    "        write_cog(\n",
    "            probability_masked,\n",
    "            fname=probabilities_filename,\n",
    "            overwrite=True,\n",
    "            nodata=255,\n",
    "        )\n",
    "\n",
    "        del probability_masked\n",
    "\n",
    "\n",
    "        del aoi_mask\n",
    "\n",
    "        # Clear the output\n",
    "        clear_output(wait=True)\n",
    "else:\n",
    "    print(\"Skipping prediction process as wetland type model is not available.\")             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f3add8-d9f1-4307-9257-877f2f09f5d4",
   "metadata": {},
   "source": [
    "#### Merge the tiles and export the final wetland predicitons and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c829c04-d609-4780-b832-a63f913d5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if type_model exists\n",
    "if 'type_model' in locals():\n",
    "    # Get the list of files in the tiles_pred folder\n",
    "    tile_files = os.listdir(tiles_pred_folder)\n",
    "\n",
    "    # Create a list to store the paths of prediction and probability files\n",
    "    prediction_files = []\n",
    "    probability_files = []\n",
    "\n",
    "    # Define the pattern for matching the filenames\n",
    "    pattern_prediction = fr\"{prefix}_tile\\d+_wetland_type_prediction.tif\"\n",
    "    pattern_probability = fr\"{prefix}_tile\\d+_wetland_type_probabilities.tif\"\n",
    "\n",
    "    # Compile the regular expression patterns\n",
    "    regex_prediction = re.compile(pattern_prediction)\n",
    "    regex_probability = re.compile(pattern_probability)\n",
    "\n",
    "    # Iterate over the tile files\n",
    "    for file in tile_files:\n",
    "        # Check if the file is a prediction file\n",
    "        if regex_prediction.match(file):\n",
    "            prediction_files.append(os.path.join(tiles_pred_folder, file))\n",
    "        # Check if the file is a probability file\n",
    "        elif regex_probability.match(file):\n",
    "            probability_files.append(os.path.join(tiles_pred_folder, file))\n",
    "\n",
    "    # Define the output mosaic filenames\n",
    "    out_mosaic_prediction = f\"{output_folder}/{prefix}/{prefix}_merged_wetland_prediction.tif\"\n",
    "    out_mosaic_probabilities = f\"{output_folder}/{prefix}/{prefix}_merged_wetland_probabilities.tif\"\n",
    "\n",
    "    # Remove the merged files if they already exist\n",
    "    if os.path.exists(out_mosaic_prediction):\n",
    "        subprocess.run(f\"rm {out_mosaic_prediction}\", shell=True)\n",
    "\n",
    "    if os.path.exists(out_mosaic_probabilities):\n",
    "        subprocess.run(f\"rm {out_mosaic_probabilities}\", shell=True)\n",
    "\n",
    "    # Merge the individual tiles into the merged files\n",
    "    merge_cmd_prediction = f\"gdal_merge.py -o {out_mosaic_prediction} -co COMPRESS=Deflate -ot Byte {' '.join(prediction_files)} -init 255 -a_nodata 255\"\n",
    "    subprocess.run(merge_cmd_prediction, shell=True)\n",
    "\n",
    "    merge_cmd_probabilities = f\"gdal_merge.py -o {out_mosaic_probabilities} -co COMPRESS=Deflate -ot Byte {' '.join(probability_files)} -init 255 -a_nodata 255\"\n",
    "    subprocess.run(merge_cmd_probabilities, shell=True)\n",
    "\n",
    "    # Load the merged predictions as xarray DataArray\n",
    "    merged_prediction = rxr.open_rasterio(out_mosaic_prediction).squeeze()\n",
    "    merged_probabilities = rxr.open_rasterio(out_mosaic_probabilities).squeeze()\n",
    "\n",
    "    # Rasterize the area of interest polygon\n",
    "    aoi_raster = xr_rasterize(gdf=geom_gdf,\n",
    "                              da=merged_prediction,\n",
    "                              crs=merged_prediction.rio.crs)\n",
    "\n",
    "\n",
    "    # Mask the wetland classes pixels within the AOI\n",
    "    wetland_type_predictions = merged_prediction.where((aoi_raster == 1) & (binary_wetland_predictions == 1))\n",
    "\n",
    "    # Define the output clipped filenames\n",
    "    clipped_prediction_file = f\"{output_folder}/{prefix}/{prefix}_wetland_type_prediction.tif\"\n",
    "    clipped_probabilities_file = f\"{output_folder}/{prefix}/{prefix}_wetland_type_probabilities.tif\"\n",
    "\n",
    "    # Write the clipped wetland predictions to file\n",
    "    write_cog(\n",
    "        wetland_type_predictions,\n",
    "        fname=clipped_prediction_file,\n",
    "        overwrite=True,\n",
    "        nodata=255,\n",
    "    )\n",
    "\n",
    "    # Clip the wetland probabilities to the AOI\n",
    "    wetland_type_probabilities = merged_probabilities.where((aoi_raster == 1) & (binary_wetland_predictions == 1))\n",
    "\n",
    "    # Write the clipped wetland probabilities to file\n",
    "    write_cog(\n",
    "        wetland_type_probabilities,\n",
    "        fname=clipped_probabilities_file,\n",
    "        overwrite=True,\n",
    "        nodata=255,\n",
    "    )\n",
    "\n",
    "    # Delete the merged files\n",
    "    if os.path.exists(out_mosaic_prediction):\n",
    "        os.remove(out_mosaic_prediction)\n",
    "\n",
    "    if os.path.exists(out_mosaic_probabilities):\n",
    "        os.remove(out_mosaic_probabilities)\n",
    "        \n",
    "else:\n",
    "    print(\"Skipping merging and clipping process as wetland type model is not available.\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479d3190-ef86-4f49-a93e-e0ae1e660eb3",
   "metadata": {},
   "source": [
    "#### Plot the wetland type predicitions and probabilities¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15a2341-9f6d-4f1a-8187-a2947cc8231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if type_model exists\n",
    "if 'type_model' in locals():\n",
    "    # Import the class label dictionary\n",
    "    with open(f'data/{prefix}_labels_dict.json', 'r') as json_file:\n",
    "        labels_dict = json.load(json_file)\n",
    "        # Remove the non-wetland class from the dictionary\n",
    "        if 0 in labels_dict.values():\n",
    "            del labels_dict['Non-wetland']    \n",
    "\n",
    "    # Generate random colors for each class (excluding class 0)\n",
    "    random.seed(42)  # Set a seed for reproducibility\n",
    "    class_colors = {class_name: f'#{random.randint(0, 255):02x}{random.randint(0, 255):02x}{random.randint(0, 255):02x}'\n",
    "                    for class_name in labels_dict}\n",
    "\n",
    "    # Create the figure and axes\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Plot wetland predictions\n",
    "    # Sort classes based on their numeric labels\n",
    "    sorted_classes = sorted(labels_dict, key=lambda x: labels_dict[x])\n",
    "\n",
    "    # Plot wetland predictions\n",
    "    cmap = ListedColormap([class_colors[class_name] for class_name in sorted_classes])\n",
    "    wetland_type_predictions.plot.imshow(ax=axes[0],\n",
    "                                    cmap=cmap,\n",
    "                                    add_colorbar=False,\n",
    "                                    interpolation='none')\n",
    "    axes[0].set_title('Wetland Predictions', fontweight='bold')\n",
    "\n",
    "    # Plot clipped wetland probabilities\n",
    "    im = wetland_type_probabilities.plot.imshow(ax=axes[1],\n",
    "                                           cmap='RdYlBu',\n",
    "                                           add_colorbar=False)\n",
    "    axes[1].set_title('Wetland Probabilities', fontweight='bold')\n",
    "\n",
    "    # Add legend to the first subplot\n",
    "    patches_list = [Patch(facecolor=class_colors[class_name]) for class_name in sorted_classes]\n",
    "    legend = axes[0].legend(patches_list, [class_name for class_name in sorted_classes],\n",
    "                            loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    # Adjust spacing\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "    # Add colorbar outside the subplot\n",
    "    cbar = fig.colorbar(im, ax=axes.ravel().tolist(), orientation='vertical', fraction=0.05, pad=0.04)\n",
    "    cbar.set_label('Wetland Probability')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping plotting process as wetland type model is not available.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0e92ef-e1b0-4afc-98fc-fdd5ae2d9a97",
   "metadata": {},
   "source": [
    "### Independent accuaracy assessment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fdaffe-0733-4e4c-b387-9a427a161f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if type_model exists\n",
    "if 'type_model' in locals():\n",
    "# Load the testing points GeoDataFrame\n",
    "    testing_points = gpd.read_file(f'data/{prefix}_testing_samples.geojson')\n",
    "\n",
    "    # Sample the predictions and probabilities at testing points\n",
    "    sampled_predictions = []\n",
    "    sampled_probabilities = []\n",
    "\n",
    "    for point in testing_points.geometry:\n",
    "        # Extract the point coordinates\n",
    "        x, y = point.x, point.y\n",
    "\n",
    "        # Sample the binary predictions at the point coordinates\n",
    "        prediction = wetland_type_predictions.sel(x=x, y=y, method='nearest').item()\n",
    "\n",
    "        # Append the sampled values\n",
    "        sampled_predictions.append(prediction)\n",
    "\n",
    "    # Add the sampled values as new columns in the GeoDataFrame\n",
    "    testing_points['sampled_predictions'] = sampled_predictions\n",
    "\n",
    "    # Calculate the number of correctly classified samples\n",
    "    correct_count = (testing_points['sampled_predictions'] == testing_points['class_id']).sum()\n",
    "\n",
    "    # Calculate the total number of samples\n",
    "    total_count = len(testing_points)\n",
    "\n",
    "    # Calculate the accuracy as a percentage\n",
    "    accuracy_percentage = (correct_count / total_count) * 100\n",
    "\n",
    "    # Print the accuracy percentage\n",
    "    print(f\"Overall Accuracy: {accuracy_percentage:.2f}%\")\n",
    "else:\n",
    "    print(\"Skipping paccuracy calculation as wetland type model is not available.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c45799-be8a-40ce-b13f-2ee9f9234eba",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Africa data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/digitalearthafrica/deafrica-sandbox-notebooks).\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481ec171-625f-44a6-9e07-aee0c4a771c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "datetime.today().strftime('%Y-%m-%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
